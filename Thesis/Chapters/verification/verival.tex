\chapter{Verification and Validation}
 Computer simulations are in many engineering applications a cost-efficient way for conducting design and performance optimalization of physical problems. However, thrusting blindly numbers generated from a computer code can prove to be naive. It doesn't take a lot of coding experience before one realizes the many things that can brake down and produce unwanted or unexpected results. 
Therefore, \textit{credability} of computational results are essential, meaning the simulation is worthy of belief or confidence \cite{Oberkampf2010}.
 \textit{Verification and validation} (VV) is the main approach for assessing and the reliability of computational simulations \cite{Sommerville2006}. The terminology of (VV) have proven unconsistent across differnt engineering disciplines due to the variety of views regarding the fundaments of the method. A thorough review considering the development of (VV) concepts and terminology during the last century are studied in \cite{Oberkampf2010}, where several attempts of definitions of \textit{verification} and \textit{validation} by different scientific communities are considered. In this thesis, the definitions provided by the \textit{American Society of Mechanical Engineers guide for Verification and Validation in Computational Solid Mechanics}  \cite{Schwer2006} are followed.

\begin{defn}
Verification: The process of determining that a computational model accurately represents
the underlying mathematical model and its solution. 
\end{defn}

\begin{defn}
Validation: The process of determining the degree to which a model is an accurate
representation of the real world from the perspective of the intended uses of the model. 
\end{defn}

Simplified \textit{verification} considers if one solves the equations right, while \textit{validation} is checking if one solves the right equations for the given problem. \cite{Roache} 

 To test a computational code for all possible parameters, conditions and applications are simply too time consuming.   Verification and validation are therefore ongoing processes, with no clear boundary of completeness unless additional requirements are specified \cite{Roache}.


%With this in mind, computer scientists and engineers need some common ground to check if a computer code works as expected. And it is here the framework of verification and validation plays and important role. \\

The goal of this chapter is to verify our implementations using the method of manufactured solution  (MMS).

\section{Verification of Code}
Verification can be devided into \textit{verification of code} and \textit{verification of calculation} [\cite{Roache2002} \cite{Oberkampf2010}


Within scientific computing a mathematical model is often the baseline for simulations of a particular problem of interest. For scientists exploring physical phenomena, the mathematical model is often on the form of systems of partial differential equations (PDE´s). A computer program therefore must evaluate  mathematical identities such a differential operators and functions in order to produce accurate solutions of the governing PDE´s. 
Through verification of code, the ultimate goal is to ensure a computer program truly represents the mathematical model, forming a basis for the given problem. \\
To accumulate sufficient evidence that a mathematical model is solved correctly by a computer code,  it must excel within predefined criteria. If the acceptance criterion is not satisfied, a coding mistake is suspected. Should the code pass the preset criteria, the code is considered verified. Different acceptance criteria with increasing rigor are found in \cite{Roache}.

\begin{itemize}
\item Simple tests
\item Code-to-code comparisons
\item Discretization error quantification
\item Convergence test
\item Order-of-accuracy tests
\end{itemize} 

The two first criteria have the advantage of complying  in the absence of exact solutions, however not as rigorous as the three final criteria. \textit{Simple tests} are applied directly on numerical solution, for example evaluating if the code preservers physical properties such as conservation laws. \textit{Code-to-code comparisons} involves comparing the numerical solution of the code to another "reference code".  However, the method proves useful only  if the same mathematical models are used and the reference code have undergone rigorous verification \cite{Roache}. \\
The final three criteria \textit{Discretization error quantification}, \textit{Convergence test}, and \textit{Order-of-accuracy tests} are all related to the discretization error  $E$, defined as,

\begin{align*}
E = u_e - u_h
\end{align*}
 where $u_e$ is the exact solution and $u_h$ is the numerical solution at a given mesh and time step. 
Hence, an exact solution for the given problem is necessarily in order to evaluate the accuracy of the discretization of the mathematical model. 
 

%\begin{quote}
%The code author defines precisely what continuum partial differential equations and continuum boundary conditions are being solved, and convincingly demonstrates that they are solved correctly, i.e., usually with some order of accuracy, and always consistently, so that as some measure of discretization (e.g. the mesh increments) $\nabla \rightarrow 0$, the code produces a solution to the continuum equations; this is Verification.
%\begin{flushright}
%\textit{--- Roache, P.J.}
%\end{flushright}
%\end{quote} 
 
 
\textit{Discretization error quantification} evaluates the quantitative error between the numerical solution and the exact solution, for a certain mesh and/or time step. Even though error quantification surpass the previous criteria presented, the approache pose two major difficulties. First, what degree of spatial and temporal resolution are needed in order to reduce the discretization error $E$. Second, is the subjective assessment of how small the error should be in order to give the code credability \cite{Roache}. Since the previous criteria is, to some degree, bounded by subjective considerations, it lacks independence from the person conducting verification. \\

\textit{Convergence tests} assumes the discretization of a PDE to be consistent, if the spatial $\nabla x$ and/or temporal $\nabla x$ refinement decreases to zero, etc $\nabla x, \nabla t \rightarrow 0$., so does the discretization error $E  \rightarrow 0$ \cite{Biggs}. The method is  more consistent in comparison with discretization error quantification critera, as the choice of discretization parameters $\nabla x, \nabla t$ are not limited to one particular  resolution. Even though the choice of temporal and spatial refinements are subjective, a reduction of the discretization error is expected for increasing temporal and spatial refinement. The method is considered the minimum criterion for rigorous code verification \cite{Roache}. \\
The final critera \textit{Order-of-accuracy}  is regarded as the most rigorous acceptance criterion for verification \cite{Biggs}, \cite{Roache}, \cite{Etienne2006}, which is employed in this thesis. In addition to error estimation and convergence of the numerical solution, the method ensure the discretization error $E$ is reduced in coordinance with the \textit{formal order of accuracy} expected from the numerical scheme. The formal order of accuracy is defined to be the theoretical rate at which the truncation error of a numerical scheme is expected to reduce. The \textit{observed order of accuracy} is the actual rate at which the dicretization error $E$ is reduced by temporal and spatial refinement, produced by our code. By monitoring the dicretization error $E$ by spatial and temporal refinements, one assumes the asymptotic behavior,

\begin{align*}
E = u_e - u_h = cH^p
\end{align*} 
where c is a constant, H is the mesh size or time step and p is the convergence rate of the numerical scheme. For convergence tests, the code is assumed verified and consistent if the discretization error is proportional to $H^p$

\subsection{Method of manufactured solution}

For conducting verification of code based on convergence tests, an exact solution of the mathematical model or PDE is needed in order to evaluate the discretization error $E$. However accurate solutions of PDE´s are limited, and often simplifications of the original problem are needed in order to produce analytically solutions for comparison. 
\textit{The method of manufactured solutions} provides a simple yet robust way of making analytic solutions for PDE´s. The problem is not attacked in a traditional way, by finding an analytic solution by retaining the overall physics defined by the model. 

Let a  partial differential equation of interest be on the form
\begin{align*}
\textbf{L}(\textbf{u}) = \textbf{f}
\end{align*}

Here \textbf{L} is a differential operator, \textbf{u} is variable the of interest, and \textbf{f} is some sourceterm.

In the method of manufactured solution one first manufactures a solution \textbf{u} for the given problem. In general, the choice of \textbf{u} will not satisfy the governing equations, producing a sourceterm  \textbf{f} after differentiation by \textbf{L}. The produced source term will cancel any imbalance formed by the manufactured solution \textbf{u} of the original problem. Therefore, the manufactured solution can be constructed without any physical reasoning, proving code verificaion as a purely a mathematical exercise were we are only interested if we are solving our equation right \cite{Roache2002}. Even though the manufactured solution \textbf{u} can be chosen independently, some guidelines have been proposed for rigirous verification( \cite{Etienne2006}, \cite{Biggs}, \cite{Roache2002}). 

\begin{itemize}
\item The manufactured solution (MS), should be composed of smooth analytic functions such as exponential, trigonometric or polynomials.
\item The MS should exercise all terms and derivatives of the PDE´s. 
\item The MS should have sufficient number of derivatives
\end{itemize}
The guidelines presented are not limitation for choosing a MS, but rather improvements for ensuring the representation of the mathematical model is thoroughly tested. 

\textit{Order-of-accuracy test} or \textit{order-of-convergence test} is the most rigorous code 


For the purpose of verification of calculation we need to calculate the error of our numerical simulation. Let $\mathbf{u}_h$ denote our numerical solution and $\mathbf{u}$ be our exact solution. By letting $|| \cdot || $ be the  $L^2$ norm, we define the error as

\begin{align*}
E = ||\mathbf{u} - \mathbf{u}_h  ||
\end{align*}

Assuming our computational mesh is constructed by equilateral triangles, and that our simulations are solved with a constant timestep, the total error contribution from the temporal and spatial 
discretized PDE can be written as

\begin{align*}
E = A \delta x^l + B \delta t^k
\end{align*}


Where A and B are constants, and l and k denote the expected convergencerate... FYLL INN REF FRA ANNET KAP OM EXPECTED CONVERGENCERATE \\. In order to evalute properties of either the spatial or temporal discretization, we must reduce the numerical error contribution of the discretization not of interest. Say we would like to evaluate the convergencerate of the spatial discretization, then the temporal error must be reduced in order to not poute.. 



To deeply verify the robustness of the method of manufactured solution,  a report regarding code verification by MMS for CFD was published by Salari and Knupp \cite{Biggs}. This thorough work applied the method for both compressible and incompressible time-dependent Navier-Stokes equation. To prove its robustness the authors deliberate implemented  code errors in a verified Navier-Stokes solver by MMS presented in the report. In total 21 blind testcases where implemented, where different approaches of verification frameworks were tested. 
Of these, 10 coding mistakes that reduces the observed order-of-accuracy was implemented. Here the method of manufactured solution captured all of them. \\




Fluid structure interaction consists of several buildingblocks of fluid and structure equations describing forces exerted from one another. With this in mind a verification of the full FSI code can be tedious as implementation errors yielding non-desired results can be hard to find. We will therefore provide verification of each buildingblock until we reach the total system of equations. \\

In the following sections we will overlook the implemented solvers. Unlesss specified, all simulations are implemented on an unit square. Simulation parameters will be reported, 

For construction of the sourceterm \textbf{f} the Unified Form Language (UFL) \cite{Project2016} provided in FEniCS Project will be used. UFL provides a simple yet powerfull method of declaration for finite element forms. An example will be provided in the Fluid Problem section. 

\subsection{Fluid Problem}
One question which arises during the construction of the manufactured solution is, which formulation of the Navier-Stokes equation do we want to calculate the sourceterm. From a numerical point of view constructing the sourceterm from the Eulerian formulation and then map the equation would be feasable. Such an apporach limits the evaluation of computational demanding routines such as the generation of the deformation gradient $\hat{F}$ and its Jacobian $\ha{J}$. Even though refinement studies of spatial and temporal discretizations are often computed on small problems, such speed-ups are important when running larger simulations. 
Recall from Chapter ??? the ALE formulation of the Navier Stokes equation. 
\begin{align*}
&\rho_f \ha{J}\pder{\hat{u}}{t} + \ha{J} \hat{F}^{-1} (\hat{u} - \hat{w})\cdot \nabla \hat{u} 
- \nabla \cdot \ha{J} \sigma \hat{F}^{-T} = f \\
&\ha{div}(\ha{J}\hat{F}^{-1}\ha{u}) = 0
\end{align*}


%\begin{lstlisting}[style=python, frame=single, title=A Fibonaci example]
\begin{lstlisting}[style=python, caption={Descriptive Caption Text}, label=DescriptiveLabel, frame=single]
u_x = "cos(x[0])*sin(x[1])*cos(t_)"
u_y = "-sin(x[0])*cos(x[1])*cos(t_)"
p_c = "sin(x[0])*cos(x[1])*cos(t_)"

f = rho*diff(u_vec, t_) + rho*dot(grad(u_vec), (u_vec - w_vec)) -
div(sigma_f(p_c, u_vec, mu))
\end{lstlisting}

We will on the basis of the presented guidelines define the manufactured solution.

\begin{align*}
u = sin(x + y + t)^2 \\
v = cos(x + y +  t)^2 \\
p = cos(x + y + t)
\end{align*}

\newpage                                                                                                                                             
\section{Validation of Code}
From a thorough process of verifying our code, we can pursue validation activities on the assumption that our computational model compute accurate solutions. As we have experienced verification of code can be a tedious task, but its complexity is reduced to issues of mathematical and numerical nature. When it comes to validation on the other hand, numerous potential problems must be assessed.  Does the mathematical model describe the the physical process of interest? What about the influence of of experimental measurement methods and their uncertainty ? But a as pointed out by /oberkampf. nevn paper of bok , a  successful validation rise thrust in our mathematical computation... FIX

In the literature several different and often conflicting definitions of validation have been proposed /Rykiel . In his thorough work Rykiel also points out a main concern over that in all the confusion, there has never been more arising demands of validating models describing the real world. \\

/Refsgaard and Henriksen (2004) has propsed the following definition which we will use  

\begin{defn} 
Model Validation: \\Substantiation that a model within its domain of applicability possesses a satisfactory range of accuracy consistent with the intended application of the model
\end{defn}

This means as /Rykiel earlier proposed, the method of validation is not some method ``for certifying the truth of current scientific understanding ... Validation means a model is acceptable for its intended use it meets specific performance requirements''.  SKRIV NOE OM TUREK HVA HVA DET EXPERIMENTET TESTER OSV

 

